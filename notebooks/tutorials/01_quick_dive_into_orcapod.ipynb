{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cdd37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import orcapod as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df42576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from orcapod.data.datagrams import DictDatagram, ArrowDatagram, DictPacket, ArrowPacket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1dfc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": \"orcapod\",\n",
    "    \"__something\": \"there\",\n",
    "    \"_another_kind\": 5,\n",
    "    \"value\": 42,\n",
    "    \"_source_value\": \"Japan\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45e2f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_datagram = DictDatagram(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01b060b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = dict_datagram.as_table(include_all_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8a867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'orcapod'}\n",
      "{'_another_kind': 5, 'value': 42}\n"
     ]
    }
   ],
   "source": [
    "stream = op.streams.ImmutableTableStream(table, tag_columns=[\"name\"])\n",
    "\n",
    "for t, p in stream:\n",
    "    print(t)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10f029b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_another_kind': None, 'value': 'Japan'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.source_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9edd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstream\u001b[49m.as_table(include_source=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'stream' is not defined"
     ]
    }
   ],
   "source": [
    "stream.as_table(include_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9bc4346b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_another_kind': 5,\n",
       " 'value': 42,\n",
       " '_context_key': 'std:v0.1.0:default',\n",
       " '__something': 'there',\n",
       " '_source__another_kind': None,\n",
       " '_source_value': None}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.as_dict(include_all_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffd88de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArrowPacket(data={'_another_kind': 5, 'value': 42}, meta_columns=1, context='std:v0.1.0:default')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93b7638a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_another_kind': None, 'value': None}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.source_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd4692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "stream = op.SyncStreamFromLists(\n",
    "    tags=[{\"id\": i} for i in range(N)],\n",
    "    packets=[{\"x\": i, \"y\": i + 1} for i in range(N)],\n",
    "    tag_typespec={\"id\": int},\n",
    "    packet_typespec={\"x\": int, \"y\": int},\n",
    "    label=\"MySource\",\n",
    ")\n",
    "\n",
    "word_stream = op.SyncStreamFromLists(\n",
    "    tags=[{\"id\": i} for i in range(N)],\n",
    "    packets=[{\"word1\": f\"hello {i}\", \"word2\": f\"world {i}\"} for i in range(N)],\n",
    "    tag_typespec={\"id\": int},\n",
    "    packet_typespec={\"word1\": str, \"word2\": str},\n",
    "    label=\"HelloWorld\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ab941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0} {'x': 0, 'y': 1}\n",
      "{'id': 1} {'x': 1, 'y': 2}\n",
      "{'id': 2} {'x': 2, 'y': 3}\n",
      "{'id': 3} {'x': 3, 'y': 4}\n",
      "{'id': 4} {'x': 4, 'y': 5}\n",
      "{'id': 5} {'x': 5, 'y': 6}\n",
      "{'id': 6} {'x': 6, 'y': 7}\n",
      "{'id': 7} {'x': 7, 'y': 8}\n",
      "{'id': 8} {'x': 8, 'y': 9}\n",
      "{'id': 9} {'x': 9, 'y': 10}\n"
     ]
    }
   ],
   "source": [
    "for tag, packet in stream:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef13511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0} {'word1': 'hello 0', 'word2': 'world 0'}\n",
      "{'id': 1} {'word1': 'hello 1', 'word2': 'world 1'}\n",
      "{'id': 2} {'word1': 'hello 2', 'word2': 'world 2'}\n",
      "{'id': 3} {'word1': 'hello 3', 'word2': 'world 3'}\n",
      "{'id': 4} {'word1': 'hello 4', 'word2': 'world 4'}\n",
      "{'id': 5} {'word1': 'hello 5', 'word2': 'world 5'}\n",
      "{'id': 6} {'word1': 'hello 6', 'word2': 'world 6'}\n",
      "{'id': 7} {'word1': 'hello 7', 'word2': 'world 7'}\n",
      "{'id': 8} {'word1': 'hello 8', 'word2': 'world 8'}\n",
      "{'id': 9} {'word1': 'hello 9', 'word2': 'world 9'}\n"
     ]
    }
   ],
   "source": [
    "for tag, packet in word_stream:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7eb5ed",
   "metadata": {},
   "source": [
    "## Defining function pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891bbadf",
   "metadata": {},
   "source": [
    "Now we define our own function pods to perform simple computation. \n",
    "Defining a function pod is quite simple, you simply \n",
    "1. define a regular function with type annotations\n",
    "2. decorate with `op.function_pod`, passing in the name ('key') for the output value(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8781072",
   "metadata": {},
   "outputs": [],
   "source": [
    "@op.function_pod(\"total\")\n",
    "def total(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "\n",
    "@op.function_pod(\"delta\")\n",
    "def delta(x: int, y: int) -> int:\n",
    "    return 2 * y - x\n",
    "\n",
    "\n",
    "@op.function_pod(\"mult\")\n",
    "def mult(x: int, y: int) -> int:\n",
    "    return x * y\n",
    "\n",
    "\n",
    "@op.function_pod(\"concat_string\")\n",
    "def concat(x: str, y: str) -> str:\n",
    "    return x + y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd843166",
   "metadata": {},
   "source": [
    "Wrapped functions are now `FunctionPod` and expects to be called with streams as inputs. You can still access the original function through its `function` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b8f8056",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected SyncStream, got int for stream 5",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# this won't work, because it's expecting a stream as input\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtotal\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/base.py:60\u001b[39m, in \u001b[36mKernel.__call__\u001b[39m\u001b[34m(self, label, *streams, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stream \u001b[38;5;129;01min\u001b[39;00m streams:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, SyncStream):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m     61\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected SyncStream, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(stream).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for stream \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstream\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     62\u001b[39m         )\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, Source):\n\u001b[32m     64\u001b[39m         \u001b[38;5;66;03m# if the stream is a Source, instantiate it\u001b[39;00m\n\u001b[32m     65\u001b[39m         stream = stream()\n",
      "\u001b[31mTypeError\u001b[39m: Expected SyncStream, got int for stream 5"
     ]
    }
   ],
   "source": [
    "# this won't work, because it's expecting a stream as input\n",
    "total(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba23537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but you can access original function this way\n",
    "total.function(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ffa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing a stream into a pod does NOT immediately trigger execution, but rather returns another stream\n",
    "\n",
    "total_stream = total(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7a165",
   "metadata": {},
   "source": [
    "Iterating through the stream or calling `flow` triggers the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9017c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tag, packet \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtotal_stream\u001b[49m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tag, packet)\n",
      "\u001b[31mNameError\u001b[39m: name 'total_stream' is not defined"
     ]
    }
   ],
   "source": [
    "for tag, packet in total_stream:\n",
    "    print(tag, packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59104716",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtotal_stream\u001b[49m.flow()\n",
      "\u001b[31mNameError\u001b[39m: name 'total_stream' is not defined"
     ]
    }
   ],
   "source": [
    "total_stream.flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1013dd1",
   "metadata": {},
   "source": [
    "If you try to pass in an incompatible stream (stream whose packets don't match the expected inputs of the function), you will immediately get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77547b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'word1' not found in parameter types.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input packet types {'word1': <class 'str'>, 'word2': <class 'str'>} is not compatible with the function's expected input types {'x': <class 'int'>, 'y': <class 'int'>}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m total_stream = \u001b[43mtotal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_stream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/base.py:75\u001b[39m, in \u001b[36mKernel.__call__\u001b[39m\u001b[34m(self, label, *streams, **kwargs)\u001b[39m\n\u001b[32m     69\u001b[39m normalized_streams = [\n\u001b[32m     70\u001b[39m     stream() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, Source) \u001b[38;5;28;01melse\u001b[39;00m stream\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m stream \u001b[38;5;129;01min\u001b[39;00m verified_streams\n\u001b[32m     72\u001b[39m ]\n\u001b[32m     74\u001b[39m pre_processed_streams = \u001b[38;5;28mself\u001b[39m.pre_forward_hook(*normalized_streams, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m output_stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpre_processed_streams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m post_processed_stream = \u001b[38;5;28mself\u001b[39m.post_forward_hook(output_stream, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# create an invocation instance\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/pod.py:236\u001b[39m, in \u001b[36mFunctionPod.forward\u001b[39m\u001b[34m(self, *streams, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m _, packet_typespec = stream.types(trigger_run=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m packet_typespec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_typespec_compatibility(\n\u001b[32m    234\u001b[39m     packet_typespec, \u001b[38;5;28mself\u001b[39m.function_input_typespec\n\u001b[32m    235\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    237\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput packet types \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket_typespec\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not compatible with the function\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms expected input types \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.function_input_typespec\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().forward(*streams, **kwargs)\n",
      "\u001b[31mTypeError\u001b[39m: Input packet types {'word1': <class 'str'>, 'word2': <class 'str'>} is not compatible with the function's expected input types {'x': <class 'int'>, 'y': <class 'int'>}"
     ]
    }
   ],
   "source": [
    "total_stream = total(word_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9c030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': int}, {'x': int, 'y': int})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can check the tag and packet types of the stream\n",
    "stream.types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34338baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': int}, {'x': int, 'y': int})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can check the tag and packet types of the stream\n",
    "stream.types()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba299b2",
   "metadata": {},
   "source": [
    "## Defining pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1dd036",
   "metadata": {},
   "source": [
    "We will now piece together multiple function pods into a pipeline. We do this by instantiating a `Pipeline` object. We will store the results into a simple data store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8083f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use simple data store, saving data to Parquet files\n",
    "from orcapod.stores.delta_table_arrow_data_store import DeltaTableArrowDataStore\n",
    "\n",
    "pipeline_store = DeltaTableArrowDataStore(\"./delta_store\", batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a475308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = op.Pipeline(\"test_pipeline\", pipeline_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42158b9",
   "metadata": {},
   "source": [
    "Now we have a pipeline object, we can use it to define our pipeline by simply \"chaining\" together function pod calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f923ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pipeline:\n",
    "    total_stream = total(stream)\n",
    "    delta_stream = delta(stream)\n",
    "    mult_stream = mult(\n",
    "        total_stream.map({\"total\": \"x\"}), delta_stream.map({\"delta\": \"y\"})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e9413",
   "metadata": {},
   "source": [
    "And that's it! Now the elements of the pipeline is available as properties on the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee41a20",
   "metadata": {},
   "source": [
    "By default, the function pods are made available under the function's name in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64746ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing packet {'x': 8, 'y': 9}: Memoizing single packet return 2 packets!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Memoizing single packet return 2 packets!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/pipeline/pipeline.py:217\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, full_sync)\u001b[39m\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m full_sync:\n\u001b[32m    216\u001b[39m         node.reset_cache()\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mself\u001b[39m.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/base.py:336\u001b[39m, in \u001b[36mStream.flow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflow\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Collection[\u001b[38;5;28mtuple\u001b[39m[Tag, Packet]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m    Flow everything through the stream, returning the entire collection of\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    (Tag, Packet) as a collection. This will tigger any upstream computation of the stream.\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/base.py:590\u001b[39m, in \u001b[36mSource.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[\u001b[38;5;28mtuple\u001b[39m[Tag, Packet]]:\n\u001b[32m    587\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[33;03m    Simple iter method that allows for Source object to act as a stream.\u001b[39;00m\n\u001b[32m    589\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/streams.py:99\u001b[39m, in \u001b[36mSyncStreamFromGenerator.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[\u001b[38;5;28mtuple\u001b[39m[Tag, Packet]]:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_consistency:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generator_factory()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/pod.py:107\u001b[39m, in \u001b[36mPod.forward.<locals>.generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    105\u001b[39m logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing packet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_handling == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_handling == \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    109\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing packet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/pod.py:94\u001b[39m, in \u001b[36mPod.forward.<locals>.generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tag, packet \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         tag, output_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m output_packet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     96\u001b[39m             logger.debug(\n\u001b[32m     97\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCall returned None as output for tag \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Skipping...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/pipeline/nodes.py:629\u001b[39m, in \u001b[36mCachedFunctionPodWrapper.call\u001b[39m\u001b[34m(self, tag, packet)\u001b[39m\n\u001b[32m    627\u001b[39m output_packet = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_memoization_lookup:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     output_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve_memoized_with_packet_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacket_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_packet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    631\u001b[39m         logger.debug(\n\u001b[32m    632\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMemoized output for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m found, skipping computation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    633\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/pipeline/nodes.py:573\u001b[39m, in \u001b[36mCachedFunctionPodWrapper._retrieve_memoized_with_packet_key\u001b[39m\u001b[34m(self, packet_key)\u001b[39m\n\u001b[32m    571\u001b[39m packets = \u001b[38;5;28mself\u001b[39m.output_converter.from_arrow_table_to_python_packets(arrow_table)\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# since memoizing single packet, it should only contain one packet\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(packets) == \u001b[32m1\u001b[39m, (\n\u001b[32m    574\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMemoizing single packet return \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(packets)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m packets!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m )\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packets[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mAssertionError\u001b[39m: Memoizing single packet return 2 packets!"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66230603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionPodNode<FunctionPod:<function _original_total at 0x7f94f6424c20>>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6587f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionPodNode<FunctionPod:<function _original_mult at 0x7fa97bea8a40>>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0dba3",
   "metadata": {},
   "source": [
    "Other implicitly created nodes such as joining of two streams are made available under the corresponding operator class (e.g. `Join`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd0dfba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelNode<Join()>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dba5c5",
   "metadata": {},
   "source": [
    "You can list out all nodes through `nodes` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e22758ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MySource': KernelNode<StreamSource>,\n",
       " 'total': FunctionPodNode<FunctionPod:<function _original_total at 0x7fa97bea8900>>,\n",
       " 'delta': FunctionPodNode<FunctionPod:<function _original_delta at 0x7fa97bea8860>>,\n",
       " 'MapPackets_0': KernelNode<packets(total ⇒ x)>,\n",
       " 'MapPackets_1': KernelNode<packets(delta ⇒ y)>,\n",
       " 'Join': KernelNode<Join()>,\n",
       " 'mult': FunctionPodNode<FunctionPod:<function _original_mult at 0x7fa97bea8a40>>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b617f",
   "metadata": {},
   "source": [
    "You can easily rename any node using the pipeline's `rename` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d1a470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.rename(\"MapPackets_0\", \"total_map\")\n",
    "pipeline.rename(\"MapPackets_1\", \"mult_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a43984d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MySource': KernelNode<StreamSource>,\n",
       " 'total': FunctionPodNode<FunctionPod:<function _original_total at 0x7fa97bea8900>>,\n",
       " 'delta': FunctionPodNode<FunctionPod:<function _original_delta at 0x7fa97bea8860>>,\n",
       " 'Join': KernelNode<Join()>,\n",
       " 'mult': FunctionPodNode<FunctionPod:<function _original_mult at 0x7fa97bea8a40>>,\n",
       " 'total_map': KernelNode<packets(total ⇒ x)>,\n",
       " 'mult_map': KernelNode<packets(delta ⇒ y)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c438f111",
   "metadata": {},
   "source": [
    "Renaming does NOT change the structure of the pipeline in anyway -- it simply changes how it's labeld for your convenience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa6107",
   "metadata": {},
   "source": [
    "### Running pipeline and accessing results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4412b1",
   "metadata": {},
   "source": [
    "Since we just created the pipeline, there are no results associated with any node. You can get [Polars](https://pola.rs) DataFrame viewing into the results through the node's `df` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96106e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing triggered!!\n"
     ]
    }
   ],
   "source": [
    "pipeline.total.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b7e59a",
   "metadata": {},
   "source": [
    "Before we run, the source nodes is also not \"recorded\" and thus will appear empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33b449b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing triggered!!\n"
     ]
    }
   ],
   "source": [
    "pipeline.MySource.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e8012",
   "metadata": {},
   "source": [
    "We can trigger the entire pipeline to run and record all results by simply calling the `run` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "189f943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n",
      "Flushing triggered!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing packet {'x': 8, 'y': 9}: Memoizing single packet return 2 packets!\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Memoizing single packet return 2 packets!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/pipeline/pipeline.py:217\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, full_sync)\u001b[39m\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m full_sync:\n\u001b[32m    216\u001b[39m         node.reset_cache()\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28mself\u001b[39m.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/base.py:336\u001b[39m, in \u001b[36mStream.flow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflow\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Collection[\u001b[38;5;28mtuple\u001b[39m[Tag, Packet]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m    Flow everything through the stream, returning the entire collection of\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    (Tag, Packet) as a collection. This will tigger any upstream computation of the stream.\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/base.py:590\u001b[39m, in \u001b[36mSource.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[\u001b[38;5;28mtuple\u001b[39m[Tag, Packet]]:\n\u001b[32m    587\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    588\u001b[39m \u001b[33;03m    Simple iter method that allows for Source object to act as a stream.\u001b[39;00m\n\u001b[32m    589\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/streams.py:99\u001b[39m, in \u001b[36mSyncStreamFromGenerator.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[\u001b[38;5;28mtuple\u001b[39m[Tag, Packet]]:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.check_consistency:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generator_factory()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/pod.py:107\u001b[39m, in \u001b[36mPod.forward.<locals>.generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    105\u001b[39m logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing packet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_handling == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.error_handling == \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    109\u001b[39m     warnings.warn(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing packet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/core/pod.py:94\u001b[39m, in \u001b[36mPod.forward.<locals>.generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tag, packet \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         tag, output_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m output_packet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     96\u001b[39m             logger.debug(\n\u001b[32m     97\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCall returned None as output for tag \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Skipping...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m             )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/pipeline/nodes.py:629\u001b[39m, in \u001b[36mCachedFunctionPodWrapper.call\u001b[39m\u001b[34m(self, tag, packet)\u001b[39m\n\u001b[32m    627\u001b[39m output_packet = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    628\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.skip_memoization_lookup:\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     output_packet = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve_memoized_with_packet_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacket_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_packet \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    631\u001b[39m         logger.debug(\n\u001b[32m    632\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMemoized output for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacket_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m found, skipping computation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    633\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/orcapod-python/src/orcapod/pipeline/nodes.py:573\u001b[39m, in \u001b[36mCachedFunctionPodWrapper._retrieve_memoized_with_packet_key\u001b[39m\u001b[34m(self, packet_key)\u001b[39m\n\u001b[32m    571\u001b[39m packets = \u001b[38;5;28mself\u001b[39m.output_converter.from_arrow_table_to_python_packets(arrow_table)\n\u001b[32m    572\u001b[39m \u001b[38;5;66;03m# since memoizing single packet, it should only contain one packet\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(packets) == \u001b[32m1\u001b[39m, (\n\u001b[32m    574\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMemoizing single packet return \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(packets)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m packets!\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m )\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packets[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mAssertionError\u001b[39m: Memoizing single packet return 2 packets!"
     ]
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1674bec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>x</th><th>y</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td></tr><tr><td>1</td><td>1</td><td>2</td></tr><tr><td>2</td><td>2</td><td>3</td></tr><tr><td>3</td><td>3</td><td>4</td></tr><tr><td>4</td><td>4</td><td>5</td></tr><tr><td>5</td><td>5</td><td>6</td></tr><tr><td>6</td><td>6</td><td>7</td></tr><tr><td>7</td><td>7</td><td>8</td></tr><tr><td>8</td><td>8</td><td>9</td></tr><tr><td>9</td><td>9</td><td>10</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "┌─────┬─────┬─────┐\n",
       "│ id  ┆ x   ┆ y   │\n",
       "│ --- ┆ --- ┆ --- │\n",
       "│ i64 ┆ i64 ┆ i64 │\n",
       "╞═════╪═════╪═════╡\n",
       "│ 0   ┆ 0   ┆ 1   │\n",
       "│ 1   ┆ 1   ┆ 2   │\n",
       "│ 2   ┆ 2   ┆ 3   │\n",
       "│ 3   ┆ 3   ┆ 4   │\n",
       "│ 4   ┆ 4   ┆ 5   │\n",
       "│ 5   ┆ 5   ┆ 6   │\n",
       "│ 6   ┆ 6   ┆ 7   │\n",
       "│ 7   ┆ 7   ┆ 8   │\n",
       "│ 8   ┆ 8   ┆ 9   │\n",
       "│ 9   ┆ 9   ┆ 10  │\n",
       "└─────┴─────┴─────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.MySource.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b69d213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>total</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>1</td></tr><tr><td>1</td><td>3</td></tr><tr><td>2</td><td>5</td></tr><tr><td>3</td><td>7</td></tr><tr><td>4</td><td>9</td></tr><tr><td>5</td><td>11</td></tr><tr><td>6</td><td>13</td></tr><tr><td>7</td><td>15</td></tr><tr><td>8</td><td>17</td></tr><tr><td>9</td><td>19</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌─────┬───────┐\n",
       "│ id  ┆ total │\n",
       "│ --- ┆ ---   │\n",
       "│ i64 ┆ i64   │\n",
       "╞═════╪═══════╡\n",
       "│ 0   ┆ 1     │\n",
       "│ 1   ┆ 3     │\n",
       "│ 2   ┆ 5     │\n",
       "│ 3   ┆ 7     │\n",
       "│ 4   ┆ 9     │\n",
       "│ 5   ┆ 11    │\n",
       "│ 6   ┆ 13    │\n",
       "│ 7   ┆ 15    │\n",
       "│ 8   ┆ 17    │\n",
       "│ 9   ┆ 19    │\n",
       "└─────┴───────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.total.df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
